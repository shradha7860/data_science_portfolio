Below is the directory for the different projects done
Regression Analysis:
* 		Linear Regression: The Linear Regression Jupyter Notebook focuses on building and evaluating a predictive model for house prices in King City. The model is trained using various features of the houses, and its performance is assessed using the R-squared (R2) score. The analysis reveals key drivers that significantly impact house prices, providing valuable insights for potential buyers and sellers.
* 		movie_rating_predictor: The Jupyter Notebook in question focuses on predicting the success of movies before their release using a dataset comprising around 4000 movies with 17 columns. The dataset includes information such as movie name, rating target audience, genre, release year, release date, score, votes, director, writer, star, country, budget, gross, company, and runtime.

Descriptive:
* 		Data Exploration: It explores financial data visualization, histogram plotting, NumPy and SciPy operations, machine learning with mlxtend for market basket analysis, control structures, prime number detection, and basic data imputation using Pandas. It demonstrates diverse aspects of data analysis and statistical operations using Python libraries.
* 		Descriptive Analysis: It explores a dataset on user behavior during website interactions, employing descriptive statistics, visualizations, and statistical tests. It analyzes factors like age, time spent, pages visited, cart items, and cart value to discern patterns influencing checkout status. The findings suggest that time spent and pages visited significantly impact checkout behavior, while age and cart metrics have less impact. The data preparation involves loading, handling missing values, and feature selection, contributing to a comprehensive analysis.
* 		Wine Test: The Notebook analyzes a wine dataset using machine learning techniques. It covers data loading, exploration, univariate and bivariate analyses, and classification model training. Visualizations include histograms, boxplots, and correlation matrices. Principal Component Analysis (PCA) is applied for dimensionality reduction. The notebook concludes with insights on the impact of independent variables on the dependent variable, providing a comprehensive overview of the dataset.

Predictive:
* 		Predicted Probability for Bank Credit: This Notebook initially utilizes Ordinary Least Squares (OLS) and Instrumental Variable Two-Stage Least Squares (IV2SLS) methods to analyze small retailers' stock performance. It then shifts to machine learning, employing logistic regression for credit rating prediction. The notebook covers data preprocessing, model training, and evaluation, including an adjustment of the prediction threshold for a desired approval rate. The results offer insights into financial ratios' significance and the predictive performance of the model.
* 		Advance Demand: It encompasses a multifaceted analysis, including Ordinary Least Squares (OLS) and Generalized Least Squares (GLS) regression, Lasso model for feature selection, and a tailored regularization forecasting model. It adeptly combines statistical methods and machine learning techniques, providing a thorough exploration of data patterns and predictive modeling.
* 		Recommendation Engine: It explores collaborative filtering-based recommendation systems using the Surprise library. It loads movie ratings and details, merges them, and applies KNNBasic models, evaluating performance through cross-validation. Additionally, it employs Singular Value Decomposition (SVD) for further recommendation analysis, highlighting predicted ratings and their comparison with the original dataset.
* 		Toronto Police Case: The Notebook explores a dataset from Toronto Police, aiming to predict the severity of incidents resulting in death or injuries. It preprocesses the data by handling missing values, dropping irrelevant columns, and encoding categorical features. A decision tree classifier is then trained and evaluated, with a focus on feature importance. The notebook also visualizes the decision tree structure for interpretability.
* 		Toronto Police Predictive Model: This Notebook utilizes Python, Pandas, and Scikit-Learn to analyze Toronto Police data. It explores and preprocesses the dataset, including handling missing values and encoding categorical variables. Machine learning models (Random Forest, Gradient Boosting, KNN, Naive Bayes) are implemented to predict neighborhood, month, and casualties, with hyperparameter tuning using GridSearchCV for optimal performance.

Cluster Models:
* 		clustering_in_class: The Jupyter notebook employs Python and libraries like NumPy, Pandas, and scikit-learn to analyze energy consumption data. It performs data preprocessing, visualizes consumption patterns, and applies KMeans clustering to identify trends. The notebook explores optimal cluster numbers and analyzes clustering results, particularly focusing on weekdays and energy consumption patterns.
* 		Clustering: It employs Python, Pandas, and scikit-learn for customer data analysis, covering cleaning, statistical summaries, and clustering techniques (K-means, DBSCAN, Affinity Propagation). Silhouette Scores evaluate cluster quality, aiding in customer segmentation. Synthetic data generation assesses clustering algorithms, guiding personalized marketing and business strategies for enhanced customer engagement and satisfaction.

Classifications:
* 		Classification Practice: The Jupyter notebook utilizes Python with NumPy, Pandas, and scikit-learn to perform a logistic regression classification on the Iris dataset. It includes data loading, preprocessing, model training, and evaluation using the F1 score. The notebook demonstrates the logistic regression model's intercept, coefficients, and assesses its performance on the Iris dataset.
* 		Ensemble Classification: This notebook compares ensemble models (Random Forest, AdaBoost, Bagging Classifier, and Voting Classifier) against baseline models (Logistic Regression, KNN). It explores a dataset through visualizations, conducts data preprocessing, and evaluates models. Hyperparameter tuning is performed, and a Voting Classifier is constructed, yielding metrics such as accuracy, precision, recall, and F1 score.
* 		Churn Modelling: The notebook starts by importing libraries and loading a churn dataset. It visually explores features like 'Geography' and 'Gender' in relation to customer churn. After preprocessing and splitting data, it trains Random Forest and Logistic Regression models. The notebook concludes with analyzing feature importance for both models, highlighting their contributions to predictions.
* 		Classification: This notebook explores user conversion characteristics by location, marketing channel, and gender, conducting ANOVA tests. It builds and evaluates Random Forest, KNN, and Naive Bayes models, with Naive Bayes (grid search) identified as optimal (70% accuracy). Practical business applications include targeted promotions on Thursdays and tailored offers, optimizing user engagement for growth.

Reinforcement Learning:
* 		deep_learning_inclass: It begins by installing TensorFlow and implementing a Deep Learning (DL) model using the MNIST dataset. It preprocesses data, builds a DL model with two dense layers, compiles it, and trains it on the training images and labels. It evaluates the DL model on the test set and compares its performance with RandomForest and Logistic Regression models, reporting accuracy scores.
* 		Machine Learning for Good Leaf Farms: This notebook explores indoor crop growth conditions, encompassing data loading, cleaning, and feature engineering. It analyzes resource usage patterns across locations, visualizing monthly trends. Additionally, machine learning models predict resource needs. The study facilitates insights into optimizing indoor farming practices for consistent and efficient crop growth.

Neural Networks:
* 		in class CNN: This notebook focuses on image classification using various convolutional neural network (CNN) architectures in TensorFlow/Keras. It loads the CIFAR-10 dataset, preprocesses the data, and builds, trains, and evaluates different models, including custom CNNs, AlexNet, VGG16, and InceptionV3. The models are compiled, trained, and their summaries and training histories are provided.
* 		Image Classification Practice: It focuses on image classification using TensorFlow and Keras, utilizing the CIFAR-10 dataset. It covers the implementation and training of several convolutional neural network (CNN) models, including a custom CNN, AlexNet, VGG16, and InceptionV3. The models are compiled, trained, and evaluated on the CIFAR-10 images, with summaries and training histories provided for analysis.
* 		Image Classification: This deep learning image classification project aimed to classify Stanford Dogs dataset breeds. Models like ResNet50 and EfficientNetB0, utilizing pre-trained weights, outperformed simpler ones. Challenges included memory constraints and data augmentation fine-tuning. Recommendations involve exploring advanced augmentation, fine-tuning hyperparameters, and potential ensembling for improved accuracy.
